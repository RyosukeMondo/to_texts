# Tasks Document

## Phase 1: Database Foundation (Est: 3-4 days)

- [x] 1. Create database models and schema
  - Files: `zlibrary_downloader/models.py` (~200 lines)
  - Define dataclasses for Book, Author, ReadingList, Download, SearchHistory
  - Follow existing Credential dataclass pattern with to_dict/from_dict methods
  - Purpose: Establish type-safe data structures for all database entities
  - _Leverage: zlibrary_downloader/credential.py (Credential dataclass pattern)_
  - _Requirements: All requirements (data foundation)_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Python Data Modeling Expert with expertise in dataclasses and type systems | Task: Create comprehensive dataclasses for Book, Author, ReadingList, Download, and SearchHistory following the exact pattern from zlibrary_downloader/credential.py including to_dict/from_dict serialization methods and proper type hints covering all database requirements | Restrictions: Must use dataclasses only (no ORM), follow Python 3.8+ compatibility, include Optional types appropriately, no complex validation logic in models (keep them simple data containers), file must be ≤200 lines | _Leverage: Read zlibrary_downloader/credential.py for the exact pattern to follow (Credential class shows serialization, Optional fields, datetime handling) | _Requirements: All requirements (provides data structures for books, authors, lists, downloads, search history) | Success: All dataclasses defined with complete type hints, to_dict/from_dict methods work correctly, follows Credential pattern exactly, passes mypy strict mode, ≤200 lines | Instructions: First edit tasks.md to change this task from [ ] to [-], implement the models, test serialization works, then change [-] to [x] in tasks.md_

- [x] 2. Create database schema SQL
  - Files: `zlibrary_downloader/schema.py` (~150 lines)
  - Define SQL schema for all tables with indexes and foreign keys
  - Include schema version tracking table
  - Purpose: Provide complete SQL schema for database initialization
  - _Leverage: Design document's database schema section_
  - _Requirements: All requirements (database structure)_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Database Designer with expertise in SQLite schema design and normalization | Task: Create schema.py module containing SQL CREATE TABLE statements for all 8 tables (books, authors, book_authors, reading_lists, list_books, saved_books, downloads, search_history) with proper indexes, foreign keys, and a schema_version table, following the database schema from the design document | Restrictions: Use SQLite-compatible SQL only, parameterized CREATE IF NOT EXISTS statements, include all indexes from design, use proper foreign key constraints with ON DELETE CASCADE, file must be ≤150 lines | _Leverage: Read design.md Data Models section for complete schema definition | _Requirements: All requirements (database structure) | Success: All tables defined with correct columns and types, indexes created on frequently queried columns (title, language, year), foreign keys with proper cascading, schema_version table included, ≤150 lines, SQL is valid SQLite syntax | Instructions: First edit tasks.md changing [ ] to [-], create schema.py with SQL strings, validate SQL syntax, then change [-] to [x] in tasks.md_

- [x] 3. Implement DatabaseManager class
  - Files: `zlibrary_downloader/db_manager.py` (~150 lines)
  - Create connection management, schema initialization, transaction support
  - Follow CredentialManager pattern for lifecycle management
  - Purpose: Manage database connection and provide transaction support
  - _Leverage: zlibrary_downloader/credential_manager.py (manager pattern), zlibrary_downloader/schema.py_
  - _Requirements: Req 8 (database operations), NFR Security, NFR Reliability_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Senior Python Developer with expertise in database connection management and SQLite | Task: Implement DatabaseManager class following CredentialManager's lifecycle pattern (init, connection management, cleanup) from zlibrary_downloader/credential_manager.py, managing SQLite connection to ~/.zlibrary/books.db (configurable via env var), providing get_connection(), initialize_schema() using schema.py, close(), and execute_transaction() methods with proper error handling | Restrictions: Must use context managers for connection management, set file permissions to 600 on Unix, enable foreign keys and WAL mode, handle connection errors gracefully, follow CredentialManager patterns exactly, file must be ≤150 lines | _Leverage: Read zlibrary_downloader/credential_manager.py for manager pattern, use zlibrary_downloader/schema.py for schema initialization | _Requirements: Req 8 (db init), NFR Security (file permissions), NFR Reliability (transactions, error handling) | Success: DatabaseManager manages connection lifecycle correctly, initialize_schema() creates all tables from schema.py, transactions work with rollback on error, file permissions set correctly, follows manager pattern, ≤150 lines, passes mypy strict | Instructions: Edit tasks.md [ ] to [-], implement DatabaseManager, test with in-memory DB, change [-] to [x] in tasks.md_

- [x] 4. Create database manager unit tests
  - Files: `tests/test_db_manager.py` (~150 lines)
  - Test connection management, schema initialization, transaction support
  - Use in-memory database for fast testing
  - Purpose: Ensure DatabaseManager reliability
  - _Leverage: tests/conftest.py (fixture patterns), tests/test_credential_manager.py (manager test pattern)_
  - _Requirements: NFR Maintainability (≥80% coverage)_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: QA Engineer with expertise in Python unit testing and pytest | Task: Create comprehensive unit tests for DatabaseManager covering connection management, schema initialization (verify all tables created), transaction support (commit and rollback), error handling, and cleanup, using in-memory SQLite (":memory:") for fast tests following existing test patterns from tests/test_credential_manager.py and using pytest fixtures from tests/conftest.py | Restrictions: Must use in-memory DB for all tests, test both success and failure scenarios, verify all tables and indexes created, test transaction rollback, ensure test isolation (each test gets fresh DB), file must be ≤150 lines, achieve ≥80% coverage of db_manager.py | _Leverage: Read tests/test_credential_manager.py for manager testing patterns, tests/conftest.py for fixture creation patterns | _Requirements: NFR Maintainability (≥80% coverage), NFR Reliability (verify error handling) | Success: All DatabaseManager methods tested, schema initialization verified, transaction rollback works, error scenarios covered, tests run independently, ≥80% coverage, ≤150 lines | Instructions: Edit tasks.md [ ] to [-], write tests, verify coverage ≥80%, change [-] to [x]_

## Phase 2: Repository Layer (Est: 4-5 days)

- [x] 5. Implement BookRepository
  - Files: `zlibrary_downloader/book_repository.py` (~250 lines)
  - Implement CRUD operations: create, get_by_id, search, update, upsert, delete, count
  - Use parameterized queries for all SQL operations
  - Purpose: Provide all book-related database operations
  - _Leverage: zlibrary_downloader/db_manager.py, zlibrary_downloader/models.py_
  - _Requirements: Req 1, 2, 3 (book storage, browse, view details)_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Backend Developer with expertise in repository pattern and SQLite | Task: Implement BookRepository class with DatabaseManager dependency injection, providing create(book), get_by_id(id), search(query, **filters) supporting language/year/format/author filters with LIKE and parameterized queries, update(book), upsert(book) for insert-or-update logic, delete(id), count(**filters) methods, all using proper parameterized queries to prevent SQL injection and returning Book dataclass instances from zlibrary_downloader/models.py | Restrictions: ALL queries must use parameterized statements (no string concatenation), use executemany() for bulk operations, implement search with proper WHERE clause building using helper methods to keep complexity ≤10, return List[Book] or Optional[Book] as appropriate, file must be ≤250 lines, each function ≤30 lines | _Leverage: Use zlibrary_downloader/db_manager.py for connection, zlibrary_downloader/models.py Book dataclass for type safety | _Requirements: Req 1 (store), Req 2 (browse with filters), Req 3 (view details), NFR Security (parameterized queries) | Success: All CRUD methods work correctly, search supports all filters, upsert logic handles insert/update, parameterized queries used everywhere, complexity ≤10 per function, ≤250 lines, ≤30 lines per function, passes mypy strict | Instructions: Edit tasks.md [ ] to [-], implement BookRepository with helper methods for query building, test each method, change [-] to [x]_

- [x] 6. Implement AuthorRepository
  - Files: `zlibrary_downloader/author_repository.py` (~100 lines)
  - Implement get_or_create for author management
  - Handle book-author relationships in book_authors table
  - Purpose: Manage authors and book-author associations
  - _Leverage: zlibrary_downloader/db_manager.py, zlibrary_downloader/models.py_
  - _Requirements: Req 1 (author extraction and linking)_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Backend Developer with expertise in database relationships and normalization | Task: Implement AuthorRepository class with DatabaseManager dependency, providing get_or_create(name) to find existing author or create new one (handling race conditions with INSERT OR IGNORE), link_book_author(book_id, author_id, order) to create book_authors relationship, get_authors_for_book(book_id) returning List[Author], and get_books_for_author(author_id) for reverse lookup, all using parameterized queries and returning Author dataclass instances | Restrictions: Must use parameterized queries exclusively, handle duplicate author names gracefully with INSERT OR IGNORE, maintain author_order in book_authors for multi-author books, file must be ≤100 lines, each function ≤30 lines | _Leverage: Use zlibrary_downloader/db_manager.py for connection, zlibrary_downloader/models.py Author dataclass | _Requirements: Req 1 (author extraction and linking) | Success: get_or_create handles duplicates correctly, book-author relationships created properly with ordering, parameterized queries used, ≤100 lines, ≤30 lines per function, passes mypy strict | Instructions: Edit [ ] to [-], implement AuthorRepository, test with duplicate names, change [-] to [x]_

- [x] 7. Implement ReadingListRepository
  - Files: `zlibrary_downloader/list_repository.py` (~200 lines)
  - Implement CRUD for reading lists and list membership
  - Support ordered book lists with position tracking
  - Purpose: Manage user-created reading lists
  - _Leverage: zlibrary_downloader/db_manager.py, zlibrary_downloader/models.py_
  - _Requirements: Req 5 (manage reading lists)_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Backend Developer with expertise in many-to-many relationships and ordering | Task: Implement ReadingListRepository class with DatabaseManager dependency, providing create_list(name, description), get_list_by_name(name), list_all(), add_book(list_id, book_id) auto-assigning next position, remove_book(list_id, book_id), get_books(list_id) returning books in position order, delete_list(list_id), all using parameterized queries and returning ReadingList dataclass instances and Book lists | Restrictions: Must use parameterized queries, handle duplicate list names with UNIQUE constraint, maintain position ordering in list_books table, use transactions for multi-step operations, file must be ≤200 lines, each function ≤30 lines | _Leverage: Use zlibrary_downloader/db_manager.py for connection and transactions, zlibrary_downloader/models.py ReadingList and Book dataclasses | _Requirements: Req 5 (create lists, add/remove books, view lists) | Success: All list operations work correctly, position ordering maintained, duplicate names prevented, transactions ensure consistency, parameterized queries used, ≤200 lines, ≤30 lines per function, passes mypy strict | Instructions: Edit [ ] to [-], implement ReadingListRepository, test list operations, change [-] to [x]_

- [x] 8. Implement DownloadRepository and SearchHistoryRepository
  - Files: `zlibrary_downloader/download_repository.py` (~120 lines), `zlibrary_downloader/search_history_repository.py` (~80 lines)
  - DownloadRepository: record_download, get_history, get_by_credential
  - SearchHistoryRepository: record_search, get_history
  - Purpose: Track downloads and searches
  - _Leverage: zlibrary_downloader/db_manager.py, zlibrary_downloader/models.py_
  - _Requirements: Req 6 (download tracking), Req 7 (search history)_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Backend Developer with expertise in audit logging and history tracking | Task: Create two repository classes: (1) DownloadRepository with record_download(book_id, credential_id, filename, path, size, status) storing download with timestamp, get_history(limit, recent_days, credential_id) with optional filters, and get_for_book(book_id); (2) SearchHistoryRepository with record_search(query, filters_json) storing search with timestamp and get_history(limit) returning recent searches, both using parameterized queries and returning Download/SearchHistory dataclass instances | Restrictions: Must use parameterized queries, store filters as JSON string in search_history, handle optional filters in get_history, file sizes ≤120 lines (download) and ≤80 lines (search), each function ≤30 lines | _Leverage: Use zlibrary_downloader/db_manager.py for connection, zlibrary_downloader/models.py Download and SearchHistory dataclasses | _Requirements: Req 6 (record and view downloads), Req 7 (record and view searches) | Success: Downloads recorded with all metadata, search history captured, filtering works correctly, parameterized queries used, ≤120 and ≤80 lines respectively, ≤30 lines per function, passes mypy strict | Instructions: Edit [ ] to [-], implement both repositories, test recording and retrieval, change [-] to [x]_

- [x] 9. Create repository unit tests
  - Files: `tests/test_book_repository.py` (~200 lines), `tests/test_author_repository.py` (~100 lines), `tests/test_list_repository.py` (~150 lines), `tests/test_download_repository.py` (~80 lines)
  - Test all repository methods with in-memory database
  - Test parameterized queries prevent SQL injection
  - Purpose: Ensure repository reliability and security
  - _Leverage: tests/conftest.py, tests/test_credential_manager.py (patterns)_
  - _Requirements: NFR Maintainability (≥80% coverage), NFR Security_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: QA Engineer with expertise in repository testing and SQL injection prevention | Task: Create comprehensive unit tests for all repository classes using in-memory SQLite, testing all CRUD methods, search filters, upsert logic, foreign key constraints, and specifically testing SQL injection prevention by attempting injection strings in search queries and verifying they're treated as literal values, following test patterns from tests/test_credential_manager.py and using pytest fixtures from tests/conftest.py | Restrictions: Must use in-memory DB for all tests, test both success and failure scenarios, verify foreign key constraints work, test SQL injection attempts safely, ensure test isolation (fresh DB per test), total files must be ≤530 lines combined (200+100+150+80), achieve ≥80% coverage per repository | _Leverage: Read tests/test_credential_manager.py for testing patterns, tests/conftest.py for fixtures, create shared repository test fixture | _Requirements: NFR Maintainability (≥80% coverage), NFR Security (verify parameterized queries work) | Success: All repository methods tested thoroughly, SQL injection prevention verified, foreign keys tested, error scenarios covered, ≥80% coverage per file, line limits met, tests run independently | Instructions: Edit [ ] to [-], write tests for each repository, verify coverage, change [-] to [x]_

## Phase 3: Service Layer (Est: 3-4 days)

- [ ] 10. Implement BookService
  - Files: `zlibrary_downloader/book_service.py` (~180 lines)
  - Orchestrate book operations across BookRepository and AuthorRepository
  - Provide high-level methods: get_book_details, browse_books, save_book, unsave_book
  - Purpose: Business logic layer for book operations
  - _Leverage: zlibrary_downloader/book_repository.py, zlibrary_downloader/author_repository.py_
  - _Requirements: Req 2 (browse), Req 3 (view details), Req 4 (save/unsave)_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Backend Developer with expertise in service layer architecture and business logic | Task: Implement BookService class taking BookRepository and AuthorRepository as dependencies, providing get_book_details(book_id) that enriches book with authors, browse_books(**filters) delegating to repository search with validation, save_book(book_id, notes, tags, priority) adding to saved_books, unsave_book(book_id), get_saved_books() returning enriched books with notes, all with proper error handling and clear error messages | Restrictions: No direct SQL queries (use repositories only), validate inputs before calling repositories, handle None returns from repositories with friendly errors, keep complexity ≤10 per function, file must be ≤180 lines, each function ≤30 lines | _Leverage: Use BookRepository for book operations, AuthorRepository for author enrichment, inject both via __init__ | _Requirements: Req 2 (browse with filters), Req 3 (view complete details), Req 4 (save/unsave with notes) | Success: All book operations work through service layer, authors properly enriched, saved books include metadata, error messages are user-friendly, no SQL in service, complexity ≤10, ≤180 lines, ≤30 lines per function, passes mypy strict | Instructions: Edit [ ] to [-], implement BookService, test with mock repositories, change [-] to [x]_

- [ ] 11. Implement SearchService
  - Files: `zlibrary_downloader/search_service.py` (~150 lines)
  - Orchestrate search with optional database storage
  - Extract authors from API response and link to books
  - Purpose: Handle search operations with database integration
  - _Leverage: zlibrary_downloader/book_repository.py, zlibrary_downloader/author_repository.py, zlibrary_downloader/search_history_repository.py, zlibrary_downloader/client.py_
  - _Requirements: Req 1 (store search results), Req 7 (search history)_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Backend Developer with expertise in API integration and data transformation | Task: Implement SearchService class taking BookRepository, AuthorRepository, and SearchHistoryRepository as dependencies, providing search_and_store(zlibrary_client, query, **filters) that calls client.search(), transforms each API result dict to Book dataclass, extracts author names from 'author' field (handle comma-separated, "and", semicolons), calls author_repo.get_or_create() for each author, calls book_repo.upsert() for each book, links authors, records search history, returns List[Book], with helper methods _extract_authors(author_str) and _store_book(book_dict) to keep complexity ≤10 | Restrictions: No direct SQL (use repositories), handle author string variations gracefully, use transactions for multi-book storage via db_manager, keep complexity ≤10 per function, file must be ≤150 lines, each function ≤30 lines | _Leverage: Use BookRepository.upsert, AuthorRepository.get_or_create and link_book_author, SearchHistoryRepository.record_search, Zlibrary client from zlibrary_downloader/client.py | _Requirements: Req 1 (store results with authors), Req 7 (record searches) | Success: Search results stored in database, authors extracted and linked correctly, search history recorded, transactions ensure consistency, complexity ≤10, ≤150 lines, ≤30 lines per function, passes mypy strict | Instructions: Edit [ ] to [-], implement SearchService, test with mock client and repos, change [-] to [x]_

- [ ] 12. Implement ListService and DownloadService
  - Files: `zlibrary_downloader/list_service.py` (~140 lines), `zlibrary_downloader/download_service.py` (~100 lines)
  - ListService: wrap ListRepository with validation and user-friendly errors
  - DownloadService: record downloads and check history
  - Purpose: Business logic for lists and downloads
  - _Leverage: zlibrary_downloader/list_repository.py, zlibrary_downloader/download_repository.py, zlibrary_downloader/book_repository.py_
  - _Requirements: Req 5 (reading lists), Req 6 (download tracking)_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Backend Developer with expertise in service orchestration and validation | Task: Create two service classes: (1) ListService with ListRepository and BookRepository dependencies, providing create_list(name, description) with duplicate name checking, add_book_to_list(list_name, book_id) verifying book exists first, remove_book_from_list, delete_list, get_all_lists, get_list_with_books(name) enriching with full book details; (2) DownloadService with DownloadRepository dependency, providing record_download(book_id, credential_id, filename, path, size), get_download_history(recent_days, credential_id), check_if_downloaded(book_id), all with clear validation and error messages | Restrictions: No direct SQL (use repositories only), validate all inputs, verify book exists before adding to list, check list exists before operations, return user-friendly errors for missing entities, file sizes ≤140 and ≤100 lines, each function ≤30 lines, complexity ≤10 | _Leverage: ListService uses ListRepository and BookRepository; DownloadService uses DownloadRepository; inject via __init__ | _Requirements: Req 5 (list CRUD, book membership), Req 6 (record downloads, view history) | Success: All list operations validated and work correctly, download recording works, error messages are clear, no SQL in services, complexity ≤10, line limits met, ≤30 lines per function, passes mypy strict | Instructions: Edit [ ] to [-], implement both services, test with mock repositories, change [-] to [x]_

- [ ] 13. Create service unit tests
  - Files: `tests/test_book_service.py` (~150 lines), `tests/test_search_service.py` (~120 lines), `tests/test_list_service.py` (~100 lines), `tests/test_download_service.py` (~80 lines)
  - Mock repository dependencies, test business logic in isolation
  - Test error handling and validation
  - Purpose: Ensure service layer reliability
  - _Leverage: tests/conftest.py, tests/mocks/ (create mock patterns)_
  - _Requirements: NFR Maintainability (≥80% coverage)_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: QA Engineer with expertise in service layer testing and mocking | Task: Create comprehensive unit tests for all service classes using mocked repository dependencies (unittest.mock.Mock or pytest-mock), testing business logic in complete isolation from database, covering all service methods, validation logic, error handling (e.g., book not found, list already exists), author extraction in SearchService with various formats ("Author1, Author2", "Author1 and Author2", etc.), following patterns from tests/test_credential_manager.py | Restrictions: Must mock ALL repository dependencies, do not use real database, test business logic only, verify repository methods called with correct parameters, test error scenarios thoroughly, total files ≤450 lines combined (150+120+100+80), achieve ≥80% coverage per service | _Leverage: Read tests/test_credential_manager.py for mocking patterns, use pytest-mock or unittest.mock, tests/conftest.py for fixtures | _Requirements: NFR Maintainability (≥80% coverage), verify business logic correctness | Success: All service methods tested with mocked dependencies, business logic verified correct, validation tested, error handling covered, author extraction tests cover various formats, ≥80% coverage per file, line limits met | Instructions: Edit [ ] to [-], write tests with mocked repositories, verify coverage, change [-] to [x]_

## Phase 4: CLI Integration (Est: 3-4 days)

- [ ] 14. Add database command group to CLI
  - Files: `zlibrary_downloader/cli.py` (modify existing, add ~200 lines total for all db commands)
  - Create `db` subcommand group with argparse
  - Add db init, browse, show, save, unsave, saved commands
  - Purpose: Provide CLI interface for database features
  - _Leverage: existing create_argument_parser(), add_search_arguments() patterns in cli.py_
  - _Requirements: Req 2, 3, 4 (browse, show, save CLI)_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: CLI Developer with expertise in argparse and command-line interface design | Task: Extend existing create_argument_parser() in zlibrary_downloader/cli.py to add new 'db' subcommand group with subparsers for: init (initialize database), browse (with filters: --language, --year-from, --year-to, --format, --author, --query, --limit), show <book-id>, save <book-id> (with --notes, --tags, --priority), unsave <book-id>, saved (list saved books), following existing argument addition patterns like add_search_arguments() | Restrictions: Must integrate with existing argument parser, follow naming conventions from existing commands, keep each command function ≤30 lines, add help text for all options, validate arguments before calling services, total addition to cli.py should be ~200 lines spread across functions, maintain file under 400 lines total (may need to extract display functions to separate module if near limit) | _Leverage: Read existing create_argument_parser() and add_search_arguments() in zlibrary_downloader/cli.py for patterns, use same argparse style | _Requirements: Req 2 (browse command with filters), Req 3 (show command), Req 4 (save/unsave/saved commands) | Success: All db commands accessible via CLI, help text clear and consistent, arguments validated properly, integrates seamlessly with existing CLI, functions ≤30 lines, cli.py stays under 400 lines (extract if needed), passes mypy strict | Instructions: Edit [ ] to [-], add db subcommand group and commands, test each command, change [-] to [x]_

- [ ] 15. Implement db command handlers
  - Files: `zlibrary_downloader/db_commands.py` (new, ~250 lines) - extract command handlers here to keep cli.py under 400 lines
  - Implement handlers: db_init, db_browse, db_show, db_save, db_unsave, db_saved
  - Use services for all operations, format output with display functions
  - Purpose: Handle database command execution
  - _Leverage: zlibrary_downloader/book_service.py, existing display_results() in cli.py_
  - _Requirements: Req 2, 3, 4_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: CLI Backend Developer with expertise in command handling and output formatting | Task: Create db_commands.py module with command handler functions: db_init_command(args) initializing database with DatabaseManager, db_browse_command(args, book_service) displaying filtered books using display_results() pattern, db_show_command(args, book_service) displaying detailed book info, db_save_command(args, book_service), db_unsave_command(args, book_service), db_saved_command(args, book_service) listing saved books, all with proper error handling and user-friendly messages | Restrictions: Must use service layer only (no direct repository calls), reuse existing display_results() from cli.py for browse output, handle errors gracefully with clear messages (e.g., "Book not found: Use 'db browse' to see available books"), keep each function ≤30 lines, file must be ≤250 lines | _Leverage: Use BookService from zlibrary_downloader/book_service.py, reuse display_results() from cli.py for consistent output, DatabaseManager for init command | _Requirements: Req 2 (browse execution), Req 3 (show execution), Req 4 (save/unsave execution) | Success: All db commands work correctly, output is user-friendly and consistent, errors handled gracefully, no direct database access, functions ≤30 lines, ≤250 lines total, passes mypy strict | Instructions: Edit [ ] to [-], implement all command handlers, test each command, change [-] to [x]_

- [ ] 16. Add --save-db flag to search command
  - Files: `zlibrary_downloader/cli.py` (modify search_books function and argument parser)
  - Integrate SearchService to optionally store results
  - Maintain backward compatibility (default: no storage)
  - Purpose: Enable database storage during search
  - _Leverage: existing search_books() function, SearchService_
  - _Requirements: Req 1 (store search results)_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Integration Engineer with expertise in backward-compatible feature additions | Task: Modify existing search_books() function in zlibrary_downloader/cli.py to add optional save_to_db parameter (default False) and search_service parameter (default None), add --save-db flag to search argument parser, when flag present initialize DatabaseManager/repositories/SearchService and call search_service.search_and_store() instead of just client.search(), display results identically with display_results(), ensure search works exactly as before when --save-db not provided (full backward compatibility) | Restrictions: Must maintain 100% backward compatibility (existing usage unchanged), --save-db is opt-in only, initialize database components only when flag present (lazy initialization), handle database errors gracefully without breaking search (show warning and continue), keep search_books() modification under 30 additional lines, use try/except for database operations | _Leverage: Existing search_books() function in cli.py, SearchService from zlibrary_downloader/search_service.py, DatabaseManager and repositories for initialization | _Requirements: Req 1 (store search results when --save-db flag used) | Success: Search works identically without --save-db (backward compatible), with --save-db stores results in database, database errors don't break search functionality, results displayed consistently either way, modification ≤30 lines, passes mypy strict | Instructions: Edit [ ] to [-], modify search command and search_books function, test both with and without flag, change [-] to [x]_

- [ ] 17. Add reading list CLI commands
  - Files: `zlibrary_downloader/db_commands.py` (add ~100 lines)
  - Implement: db list-create, db list-show, db list-add, db list-remove, db list-delete, db lists
  - Purpose: Full reading list management from CLI
  - _Leverage: zlibrary_downloader/list_service.py_
  - _Requirements: Req 5 (reading list management)_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: CLI Developer with expertise in subcommand design and user experience | Task: Extend zlibrary_downloader/db_commands.py with reading list command handlers: db_list_create_command(args, list_service) creating list with name and optional description, db_list_show_command(args, list_service) displaying books in list, db_list_add_command(args, list_service) adding book to list by book-id, db_list_remove_command(args, list_service) removing book from list, db_list_delete_command(args, list_service) deleting list with confirmation prompt, db_lists_command(args, list_service) listing all reading lists with book counts, all with clear output and error messages | Restrictions: Must use ListService only, format output nicely (tables or lists), include confirmation for destructive operations (delete), show book counts in list display, handle errors gracefully (list not found, book not in list, etc.), keep each function ≤30 lines, total addition ≤100 lines to db_commands.py | _Leverage: Use ListService from zlibrary_downloader/list_service.py, follow patterns from other db commands in same file | _Requirements: Req 5 (create, show, add, remove, delete lists) | Success: All list commands work correctly, output is clear and user-friendly, destructive operations ask for confirmation, error handling is robust, functions ≤30 lines, addition ≤100 lines, passes mypy strict | Instructions: Edit [ ] to [-], extend db_commands.py with list handlers, add corresponding subparsers in cli.py, test all list operations, change [-] to [x]_

- [ ] 18. Add download tracking and database utilities
  - Files: `zlibrary_downloader/cli.py` (modify download_book to record downloads), `zlibrary_downloader/db_commands.py` (add ~80 lines for stats/export/import)
  - Auto-record downloads in download_book() function
  - Add db downloads, db stats, db export, db import, db vacuum commands
  - Purpose: Complete database functionality
  - _Leverage: existing download_book(), DownloadService, repositories for stats/export_
  - _Requirements: Req 6 (download tracking), Req 8 (database operations)_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Full-stack Developer with expertise in data import/export and system integration | Task: (1) Modify existing download_book() function in zlibrary_downloader/cli.py to optionally initialize DownloadService and call record_download() after successful download (lazy init, try/except for db errors), add 10-15 lines; (2) Extend zlibrary_downloader/db_commands.py with: db_downloads_command(args, download_service) showing download history with optional --recent and --credential filters, db_stats_command(args, db_manager) displaying database statistics (total books, by language/format, total downloads, db file size), db_export_command(args, book_repo) exporting all books to JSON/CSV with --format and --output options, db_import_command(args, book_repo, author_repo) importing books from JSON file with progress indicator, db_vacuum_command(args, db_manager) optimizing database | Restrictions: Download tracking must not break downloads (use try/except), stats should query efficiently (use COUNT queries), export must handle large datasets (streaming if possible), import must validate JSON structure, vacuum should explain what it does, functions ≤30 lines, total addition ≤80 lines to db_commands.py | _Leverage: Modify download_book() in cli.py (keep under 30 lines total), use DownloadService for tracking, BookRepository for export/import, DatabaseManager for stats/vacuum | _Requirements: Req 6 (download tracking and history), Req 8 (stats, export, import, vacuum) | Success: Downloads automatically tracked when database initialized, all utility commands work correctly, export/import handle large data, stats are informative, functions ≤30 lines, additions meet line limits, passes mypy strict | Instructions: Edit [ ] to [-], modify download_book and add utility commands, test tracking and utilities, change [-] to [x]_

## Phase 5: Integration Testing & Polish (Est: 2-3 days)

- [ ] 19. Create CLI integration tests
  - Files: `tests/test_cli_db_integration.py` (~250 lines)
  - Test end-to-end workflows: search→store→browse→save→list operations
  - Use temp database and mock Z-Library client
  - Purpose: Ensure all components work together
  - _Leverage: tests/test_cli_integration.py (existing integration test patterns), tests/conftest.py_
  - _Requirements: All requirements (integration verification)_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: QA Integration Engineer with expertise in end-to-end testing and test scenarios | Task: Create comprehensive integration tests in tests/test_cli_db_integration.py using temp database (pytest tmp_path fixture) and mocked Zlibrary client, testing complete workflows: (1) search with --save-db stores books, (2) browse database shows stored books with filters working, (3) show book displays correct details, (4) save book then list saved books, (5) create reading list, add books, view list, (6) download tracking records correctly, (7) export to JSON and import into fresh database, following patterns from tests/test_cli_integration.py | Restrictions: Must use temp database (tmp_path fixture), mock Zlibrary client responses, test actual CLI functions not subprocess calls (unit-style integration), verify database state after operations, ensure test isolation (fresh DB per test), file must be ≤250 lines, achieve >80% coverage of integration paths | _Leverage: Read tests/test_cli_integration.py for integration test patterns, use tests/conftest.py fixtures, create temp database fixture | _Requirements: All requirements (verify complete feature works end-to-end) | Success: All major workflows tested and passing, database operations verified, integration between components confirmed, ≤250 lines, >80% integration path coverage | Instructions: Edit [ ] to [-], write integration tests, verify all workflows, change [-] to [x]_

- [ ] 20. Add user documentation
  - Files: `docs/database-guide.md` (new, ~300 lines), update `README.md` (add ~50 lines)
  - Document all database features with examples
  - Add quick start guide and troubleshooting
  - Purpose: Enable users to use database features
  - _Leverage: existing README.md structure, docs/ directory_
  - _Requirements: All requirements (user documentation)_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Technical Writer with expertise in CLI tool documentation and user guides | Task: Create docs/database-guide.md with: (1) Quick Start section showing basic --save-db usage and browse, (2) Complete Reference for all db commands with examples, (3) Common Workflows section (building a catalog, creating reading lists, tracking downloads), (4) Troubleshooting section (database locked, corruption, permissions), (5) Advanced Topics (export/import, database maintenance); also update README.md to add Database Features section with brief overview and link to guide, following existing README structure | Restrictions: Must include practical examples for every command, write for non-technical users, include screenshots of output (ASCII art or code blocks), troubleshooting should address actual error messages users will see, keep database-guide.md ≤300 lines, README addition ≤50 lines | _Leverage: Review existing README.md for style and structure, analyze db_commands.py for accurate command syntax | _Requirements: All requirements (comprehensive user documentation) | Success: Documentation is clear and comprehensive, all commands documented with examples, troubleshooting covers common issues, README updated appropriately, line limits met | Instructions: Edit [ ] to [-], write documentation, review for clarity, change [-] to [x]_

- [ ] 21. Performance testing and optimization
  - Files: `tests/test_performance.py` (new, ~120 lines)
  - Test performance with large datasets (1000-10000 books)
  - Verify all operations meet performance requirements from NFR
  - Purpose: Ensure scalability and performance
  - _Leverage: python time module, pytest benchmarking_
  - _Requirements: NFR Performance (query times, bulk operations)_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Performance Engineer with expertise in database optimization and benchmarking | Task: Create tests/test_performance.py with performance tests using in-memory database and pytest: test_bulk_insert_performance() inserting 100 books should complete <1s, test_search_performance_large_db() searching 10000 books should complete <200ms, test_browse_with_filters_performance() with complex filters should complete <200ms, test_upsert_performance() upserting existing books should be fast, use time.time() for timing and assert against NFR requirements, include setup of large datasets | Restrictions: Must use in-memory DB for consistent results, tests should be repeatable, assert against NFR Performance requirements from requirements.md (queries <100ms, bulk <1s, search <200ms), if tests fail identify bottlenecks and add database indexes or optimize queries, file must be ≤120 lines | _Leverage: Use in-memory SQLite for consistent performance, python time module, review NFR Performance requirements in requirements.md | _Requirements: NFR Performance (verify all performance targets met) | Success: All performance tests pass meeting NFR requirements, performance is measured accurately, bottlenecks identified if any, ≤120 lines | Instructions: Edit [ ] to [-], write performance tests, run and verify passing, optimize if needed, change [-] to [x]_

- [ ] 22. Final integration, code review, and cleanup
  - Files: All implementation files
  - Run all quality gates (mypy, flake8, black, radon, line count, function size, coverage)
  - Fix any violations, optimize complex functions
  - Update CHANGELOG.md
  - Purpose: Ensure all code quality standards met
  - _Leverage: pre-commit hooks, quality check scripts_
  - _Requirements: NFR Maintainability (all quality gates)_
  - _Prompt: Implement the task for spec database-storage, first run spec-workflow-guide to get the workflow guide then implement the task: Role: Senior Developer and Code Quality Specialist with expertise in Python best practices | Task: (1) Run pre-commit hooks on all new/modified files: mypy zlibrary_downloader, flake8 zlibrary_downloader, black --check zlibrary_downloader, radon cc --min C zlibrary_downloader, python scripts/validate_line_count.py (all files), python scripts/validate_function_size.py (all files), pytest --cov=zlibrary_downloader --cov-fail-under=80; (2) Fix all violations: refactor complex functions (complexity >10), split large functions (>30 lines), split large files (>400 lines) if needed, add missing type hints, fix linting errors; (3) Update CHANGELOG.md with all new features; (4) Review all error messages for user-friendliness | Restrictions: Must pass ALL quality gates, no exceptions, functions must be ≤30 lines and ≤10 complexity, files must be ≤400 lines, coverage must be ≥80%, all type hints must pass strict mypy, if files are over limit split them into smaller focused modules | _Leverage: Use pre-commit hooks from .pre-commit-config.yaml, scripts/validate_line_count.py, scripts/validate_function_size.py, pytest-cov | _Requirements: NFR Maintainability (all code quality standards, file size, function size, complexity, coverage, type safety) | Success: All pre-commit hooks pass, all quality gates met (100% compliance), coverage ≥80% overall, CHANGELOG.md updated, code is production-ready | Instructions: Edit [ ] to [-], run all checks, fix violations iteratively, verify all pass, update CHANGELOG, change [-] to [x]_
